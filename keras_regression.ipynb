{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the dataset. We work with one-dimensional feature vectors, with feature values generated uniformly in $[-5,5]$. The target values will be normally distributed around a cubic function of the feature values, with the law\n",
    "\n",
    "$$\n",
    "y = F(x) = x^3 - \\frac{1}{2}\\,x^2 + 20\\,x\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.uniform(-5.0, 5.0, size=(1000,1))\n",
    "Y = np.random.normal(X**3 - 5.0*X**2 + 20.0*X, 50.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = go.Scatter(\n",
    "    x = X[:,0],\n",
    "    y = Y[:,0],\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        size = 3\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "layout = go.Layout(\n",
    "    xaxis = dict(\n",
    "        title = 'x'\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'y'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the neural network with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For general advice on nonlinear regression using Keras, see: https://github.com/keras-team/keras/issues/1874"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.metrics import mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape=(1,)))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common issue when doing regression with neural network is the __exploding gradients problem__, where the loss function diverges during the training phase. In this case, it was sufficient to switch from stochastic gradient descent to an Adam optimizer to solve that.\n",
    "\n",
    "For information about the exploding gradients problem, see:\n",
    "- https://stackoverflow.com/questions/37232782/nan-loss-when-training-regression-network\n",
    "- http://neuralnetworksanddeeplearning.com/chap5.html\n",
    "\n",
    "For information about the Adam optimizer, see: https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mse']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the neural network to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X, Y, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a new dataset and get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = np.linspace(-10.0, 10.0, 1000).reshape((1000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_data = go.Scatter(\n",
    "    x = X[:,0],\n",
    "    y = Y[:,0],\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        size = 3\n",
    "    ),\n",
    "    name = 'data'\n",
    ")\n",
    "\n",
    "trace_pred = go.Scatter(\n",
    "    x = X_pred[:,0],\n",
    "    y = Y_pred[:,0],\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        size = 3\n",
    "    ),\n",
    "    name = 'predictions'\n",
    ")\n",
    "\n",
    "data = [trace_data, trace_pred]\n",
    "\n",
    "layout = go.Layout(\n",
    "    xaxis = dict(\n",
    "        title = 'x'\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        title = 'y'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
